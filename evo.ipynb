{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_width = 256 #4096\n",
    "# 8k context\n",
    "seq_len = 50\n",
    "device = 'mps'\n",
    "batch_size = 1\n",
    "\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, model_width, seq_len):\n",
    "        super(RoPE, self).__init__()\n",
    "        self.model_width = model_width\n",
    "        mask = torch.cat([torch.ones(model_width, device=device), torch.zeros(model_width, device=device)], dim=0)\n",
    "        mask = mask.view(2, -1).transpose(1,0).flatten()[: model_width]\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "        thetas = torch.arange(0, self.model_width // 2, device=device)\n",
    "        thetas = -2 * (thetas - 1) / self.model_width\n",
    "        thetas = torch.exp(np.log(10000) * thetas)\n",
    "        thetas_repeated = thetas.repeat_interleave(2) * torch.arange(0, seq_len, device=device).view(-1, 1)  # seq_len, model_width\n",
    "        self.register_buffer(\"thetas_repeated\", thetas_repeated)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, l, w = x.shape\n",
    "        cos_terms = self.thetas_repeated.cos() * x\n",
    "        swapped = x.view(-1, 2).flip(1).reshape(b, l, -1)\n",
    "        sin_terms = self.thetas_repeated.sin() * swapped\n",
    "        return cos_terms + sin_terms * self.mask\n",
    "\n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, inner_dim, num_heads):\n",
    "        super(Attention, self).__init__()\n",
    "        self.inner_dim = inner_dim\n",
    "        self.to_qkv = nn.Linear(model_width, 3 * num_heads * inner_dim)\n",
    "        self.to_out = nn.Linear(num_heads * inner_dim, model_width)\n",
    "        self.num_heads = num_heads\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        self.rope = RoPE(model_width=inner_dim, seq_len=seq_len)\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x)\n",
    "        q,k,v = qkv.chunk(3, dim=-1)\n",
    "        factor = self.inner_dim ** -0.5\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.inner_dim).transpose(1,2)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.inner_dim).transpose(1,2)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.inner_dim).transpose(1,2)\n",
    "\n",
    "        q = self.rope(q.view(batch_size * self.num_heads, seq_len, -1).contiguous()).view(batch_size, self.num_heads, seq_len, -1)\n",
    "        k = self.rope(k.view(batch_size * self.num_heads, seq_len, -1).contiguous()).view(batch_size, self.num_heads, seq_len, -1)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * factor\n",
    "        attn = attn.masked_fill(self.mask[:seq_len, :seq_len] == 0, float('-inf'))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = (attn @ v).transpose(1,2).reshape(batch_size, seq_len, -1)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class MoeFFN(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 3),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 3, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, inner_dim, num_experts=8):\n",
    "        super().__init__()\n",
    "        self.gating_function = MoeFFN(inner_dim)\n",
    "        self.experts = nn.ModuleList([MoeFFN(inner_dim) for _ in range(num_experts)])\n",
    "    def forward(self, vector_in):\n",
    "        b, l, d = vector_in.shape\n",
    "        vector_in = vector_in.reshape(b*l, d)   \n",
    "        \n",
    "        x = self.gating_function(vector_in)\n",
    "        topk_values, topk_indices = x.topk(k=2, dim=-1) # (B, l, 2)\n",
    "        topk_values = topk_values.softmax(dim=-1) # (B, l, 2)\n",
    "        \n",
    "        all_expert_output = torch.zeros_like(vector_in) # (B, l, d)\n",
    "\n",
    "        for expert_idx in range(len(self.experts)):\n",
    "            expert_mask = (topk_indices == expert_idx).any(dim=-1) \n",
    "            \n",
    "            # Get the weights where this expert was selected\n",
    "            expert_locations = (topk_indices == expert_idx) \n",
    "            expert_weights = torch.zeros_like(vector_in[:, 0])\n",
    "            expert_weights[expert_mask] = topk_values[expert_locations]\n",
    "            \n",
    "            expert_tokens = vector_in[expert_mask] \n",
    "            if expert_tokens.size(0) > 0:\n",
    "                local_expert_output = self.experts[expert_idx](expert_tokens)\n",
    "                all_expert_output[expert_mask] += local_expert_output * expert_weights[expert_mask].unsqueeze(-1)\n",
    "\n",
    "            return all_expert_output.reshape(b, l, -1)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, inner_dim, num_heads):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attn = Attention(inner_dim, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(model_width)\n",
    "        self.norm2 = nn.LayerNorm(model_width)\n",
    "        self.num_experts = 8\n",
    "        self.moe = MoE(model_width, self.num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.moe(self.norm2(x))\n",
    "        return x\n",
    "        \n",
    "\n",
    "class ConvProjection(nn.Module):\n",
    "    def __init__(self, inner_dim, order=2, kernel_size=10):\n",
    "        super(ConvProjection, self).__init__()\n",
    "        self.inner_dim = inner_dim\n",
    "        self.order = order\n",
    "        self.linear_proj = nn.Linear(model_width, inner_dim * (self.order + 1))\n",
    "        # this is a depthwise conv\n",
    "        # meaning each feature for each timestep is convolved with a different filter\n",
    "        self.conv_filter = nn.Conv1d(\n",
    "            in_channels=inner_dim * (order + 1),\n",
    "            out_channels=inner_dim * (order + 1),\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "            groups=1)\n",
    "\n",
    "    def forward(self, u):\n",
    "        # u is an L x model_width tensor\n",
    "        x = self.linear_proj(u) # B x L x (inner_dim * (order + 1))\n",
    "        x = x.transpose(1, 2) # B x (inner_dim * (order + 1)) x L\n",
    "        x = self.conv_filter(x) # no change in shape\n",
    "        projections = x.chunk(self.order + 1, dim=-2) # B x inner_dim x L\n",
    "        return projections\n",
    "\n",
    "\n",
    "class HyenaFilter(nn.Module):\n",
    "    def __init__(self, inner_dim, order):\n",
    "        super(HyenaFilter, self).__init__()\n",
    "        self.inner_dim = inner_dim\n",
    "        self.t_embed = nn.Embedding(seq_len, model_width)\n",
    "        self.order = order\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(model_width, inner_dim * self.order),\n",
    "            Sine(),\n",
    "            nn.Linear(inner_dim * self.order, inner_dim * self.order),\n",
    "        )\n",
    "        # N parameters, one for each filter\n",
    "        # the alphas should be positive so we don't explode -> exp decay\n",
    "        self.alphas = nn.Parameter(torch.rand(self.order))\n",
    "        self.biases = nn.Parameter(torch.zeros(self.order))\n",
    "\n",
    "    def forward(self, batch_size, L):\n",
    "        t = torch.arange(L, device=device).unsqueeze(0).expand(batch_size, -1) # (B,L)\n",
    "        t_embed = self.t_embed(t) # (B, L, model_width)\n",
    "        x = self.ffn(t_embed) # (B, L, inner_dim * N)\n",
    "        h_hat = x.reshape(batch_size, self.order, self.inner_dim, L) # (B, N, inner_dim, L)\n",
    "        # expanded times\n",
    "        expanded_t = t.unsqueeze(1).expand(batch_size, self.order, -1) # (B, N, L)\n",
    "        expanded_alphas = self.alphas.unsqueeze(0).unsqueeze(2).expand(batch_size, -1, L) # (B, N, L)\n",
    "        expanded_biases = self.biases.unsqueeze(0).unsqueeze(2).expand(batch_size, -1, L) # (B, N, L)\n",
    "        window = (expanded_alphas * expanded_t).neg().exp() + expanded_biases # (B, N, L)\n",
    "        expanded_window = window.unsqueeze(2).expand(-1, -1, self.inner_dim, -1) # (B, N, inner_dim, L)\n",
    "        h = h_hat * expanded_window\n",
    "        return [t.squeeze(0) for t in torch.chunk(h, self.order, dim=1)]\n",
    "\n",
    "\n",
    "class HyenaBlock(nn.Module):\n",
    "    def __init__(self, order):\n",
    "        super(HyenaBlock, self).__init__()\n",
    "        self.conv_proj = ConvProjection(inner_dim=model_width, order=order)\n",
    "        self.filters = HyenaFilter(inner_dim=model_width, order=order)\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, u):\n",
    "        projs = self.conv_proj(u)\n",
    "        filters = self.filters(batch_size, seq_len)\n",
    "        assert len(projs) == len(filters) + 1\n",
    "        v = projs[0] # (B, model_width, L)\n",
    "        for n in range(self.order):\n",
    "            proj = projs[n+1] # (B, model_width, L)\n",
    "            filter = filters[n] # (B, model_width, L)\n",
    "            value_fourier = torch.fft.fft(v)\n",
    "            filter_fourier = torch.fft.fft(filter)\n",
    "            convolved_fourier = value_fourier * filter_fourier\n",
    "            convolved = torch.fft.ifft(convolved_fourier).real\n",
    "            v = proj * convolved\n",
    "        return v.transpose(1,2) # (B, L, model_width)\n",
    "\n",
    "class StripedHyenaBlock(nn.Module):\n",
    "    def __init__(self, inner_dim):\n",
    "        super(StripedHyenaBlock, self).__init__()\n",
    "        self.conv_proj = ConvProjection(inner_dim=inner_dim, order=2)\n",
    "        self.filters = HyenaFilter(inner_dim=inner_dim, order=1)\n",
    "\n",
    "    def forward(self, u):\n",
    "        q,k,v = self.conv_proj(u)\n",
    "        h, = self.filters(batch_size, seq_len)\n",
    "        v = k * v\n",
    "        value_fourier = torch.fft.fft(v)\n",
    "        filter_fourier = torch.fft.fft(h)\n",
    "        convolved_fourier = value_fourier * filter_fourier\n",
    "        convolved = torch.fft.ifft(convolved_fourier).real\n",
    "        v = q * convolved\n",
    "        return v.transpose(1,2) # (B, L, model_width)\n",
    "\n",
    "class StripedHyena(nn.Module):\n",
    "    def __init__(self, num_layers=32, spacing=10):\n",
    "        super(StripedHyena, self).__init__()\n",
    "        self.base_embed = nn.Embedding(4, model_width)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Sequential(StripedHyenaBlock(inner_dim=model_width), nn.Linear(model_width, model_width * 2), nn.GLU()) if (i+1) % spacing != 0\n",
    "            else AttentionBlock(inner_dim=128, num_heads=4)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(model_width)\n",
    "        self.to_logits = nn.Linear(model_width, 4)\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        x = self.base_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "             \n",
    "        x = self.norm(x)\n",
    "        logits = self.to_logits(x)\n",
    "        if target is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, 4), target.view(-1))\n",
    "            return loss\n",
    "        # return F.softmax(logits[:, -1, :], dim=-1)\n",
    "\n",
    "u = torch.randint(0, 4, (batch_size, seq_len)).to(device)\n",
    "model = StripedHyena(num_layers=32, spacing=10).to(device)\n",
    "model(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
